{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   time_created date_created  up_votes  down_votes  \\\n",
      "0    1201232046   2008-01-25         3           0   \n",
      "1    1201232075   2008-01-25         2           0   \n",
      "2    1201232523   2008-01-25         3           0   \n",
      "\n",
      "                               title  over_18 author  subreddit  \n",
      "0  Scores killed in Pakistan clashes    False  polar  worldnews  \n",
      "1   Japan resumes refuelling mission    False  polar  worldnews  \n",
      "2    US presses Egypt on Gaza border    False  polar  worldnews  \n"
     ]
    }
   ],
   "source": [
    "# I followed this tutorial : https://www.youtube.com/watch?v=Z1VsHYcNXDI \n",
    "# Basically this is the code they used : \n",
    "\n",
    "# pip install gensim\n",
    "# pip install nltk\n",
    "\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "import pandas as pd\n",
    "import nltk # Natural Language ToolKit\n",
    "import tqdm # shows progress bar when running long tasks\n",
    "\n",
    "df = pd.read_csv('C:/Users/nadia/Downloads/worldnews.csv')\n",
    "print(df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\nadia\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "100%|██████████| 509236/509236 [02:34<00:00, 3287.14it/s]\n"
     ]
    }
   ],
   "source": [
    "newsTitles = df['title'].values\n",
    "\n",
    "# run this one only once :\n",
    "nltk.download('punkt')\n",
    "\n",
    "newsVec = [nltk.word_tokenize(title) for title in tqdm.tqdm(newsTitles)] # tqdm just shows a progress bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('woman', 0.9663079977035522),\n",
       " ('boy', 0.9062690138816833),\n",
       " ('girl', 0.9055513739585876),\n",
       " ('couple', 0.8980273008346558),\n",
       " ('teenager', 0.8855070471763611),\n",
       " ('mother', 0.8812868595123291),\n",
       " ('doctor', 0.8733051419258118),\n",
       " ('family', 0.8559529185295105),\n",
       " ('father', 0.8469634652137756),\n",
       " ('teacher', 0.8403342366218567)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Word2Vec(newsVec, min_count=1, vector_size=32)\n",
    "model.wv.most_similar('man')\n",
    "\n",
    "# There's a bunch of other interesting functions we can use later"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7de754ff37acf7f01d8d4dc55e93ff78cd9a2e68e81afd90e372f1209c0ca5a9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
